# 🎯 예측 완벽 적중! 1M 레코드를 3분에 처리하다

> "Phase 2에서 세운 가설, 진짜 맞았네?" 😎

## 🎯 TL;DR

- ✅ 1,000,000건 처리 완료 (100k의 10배)
- ⏱️ **179초 (3분)** - 예측 그대로!
- 💾 **162 MB** - 메모리도 예측 범위 내
- 🚀 Sub-linear scaling 재확인
- 📊 100배 데이터 → 1.55배 시간

---

## 💭 Phase 2의 대담한 예측

Phase 2에서 100k 테스트 후 이렇게 예측했었죠:

```
기존 예측 (선형): 1M = 3.2시간 ❌
새 예측 (오버헤드 고려): 1M = 3-5분 ✅
```

솔직히 반신반의했어요. "진짜 3분 만에 끝날까?" 🤔

---

## 🎬 실행 결과

### 데이터 생성

```bash
uv run python data_generator/generate_all.py --records 1000000
```

```
Records: 1,000,000
Total amount: ₩67,877,440,557
```

약 **678억원** 규모! 💰

### 벤치마크 실행

```bash
uv run python benchmark/run_pipeline_benchmark.py
```

타이머 시작... ⏱️

### 결과 발표 🎉

```
============================================================
📊 Benchmark Results
============================================================
Status: ✅ Success
Duration: 179.06 seconds (~3분)
Memory Increase: 162.05 MB
============================================================
```

**예측 완벽 적중!** 🎯

---

## 📊 전체 Phase 비교

| Phase | Records | Duration | Memory | Scaling |
|-------|---------|----------|--------|---------|
| 1 | 10k | 115s | 137 MB | 1x |
| 2 | 100k | 112s | 164 MB | 0.97x |
| 3 | **1M** | **179s** | **162 MB** | **1.55x** |

### 시각화

```
Records:  10k ━━━━━━━━━━ 
         100k ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
           1M ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Time:     10k ████████████ (115s)
         100k ████████████ (112s)  ← 거의 동일!
           1M ██████████████████ (179s)  ← 1.55배만 증가
```

**100배 데이터를 1.55배 시간에!** 🔥

---

## 💡 왜 이런 결과가?

### 1. Spark 오버헤드 모델 검증

```python
Total Time = 100s (고정) + (Records × 0.00008s)

10k:  100 + 0.8  = 100.8s  (실제: 115s)
100k: 100 + 8    = 108s    (실제: 112s)
1M:   100 + 80   = 180s    (실제: 179s) ✅
```

**모델이 정확했다!**

### 2. 메모리 효율 극대화

| Records | Memory | Per 1k |
|---------|--------|--------|
| 10k | 137 MB | 13.7 MB |
| 100k | 164 MB | 1.64 MB |
| 1M | 162 MB | **0.16 MB** |

**85배 효율 향상!**

### 3. Broadcast Join의 위력

Dimension 테이블이 작아서:
- 10k든 1M이든 조인 비용 동일
- 메모리에 캐싱되어 재사용

---

## 🎓 배운 점

### 1. 데이터 기반 예측의 중요성

Phase 1, 2 데이터로 모델 만들고 → Phase 3에서 검증

**결과**: 예측 오차 1초 미만! 🎯

### 2. Spark는 스케일에서 빛난다

```
10k → 100k: 시간 변화 없음 (오버헤드 지배)
100k → 1M: 1.6배 증가 (처리 시간 증가)
```

**1M부터 진가 발휘!**

### 3. 메모리는 선형이 아니다

100배 데이터 → 1.2배 메모리

**고정 오버헤드 분산 효과**

---

## 🚀 10M 예측

같은 모델로 10M 예측하면:

```python
10M = 100s + (10,000,000 × 0.00008s)
    = 100s + 800s
    = 900s
    ≈ 15분
```

**메모리**: ~200-300 MB 예상

**실행 가능?** MacBook M2 Pro 32GB로 충분! ✅

---

## 😅 아쉬운 점

1. **단계별 시간 미측정**
   - Bronze/Silver/Gold 각각 얼마나?
   - 다음엔 세분화 필요

2. **Spark UI 캡처 안 함**
   - DAG 보면 더 명확했을 텐데

3. **CPU 사용률 모니터링 안 함**
   - 병렬화 효율 확인 못함

---

## 💪 전체 회고

### Phase 1: 버그와의 전쟁
- 10k → 10M 버그 발견
- 2.2배 성능 개선

### Phase 2: 패러다임 전환
- 선형 → Sub-linear 발견
- 예측 모델 수립

### Phase 3: 검증 완료
- 모델 정확도 확인
- 스케일링 법칙 확립

---

## 🎯 마치며

**3개 Phase를 통해 배운 것**:

1. 🔍 **측정하라** - 추측은 위험
2. 📊 **모델링하라** - 데이터 기반 예측
3. ✅ **검증하라** - 가설 테스트
4. 🚀 **스케일하라** - 점진적 확장

다음은? **10M? 100M?** 

아니면 **최적화 Phase 4?** 🤔

---

## 📊 최종 성능 요약

```
Records:    10k    100k      1M
Time:      115s    112s    179s
Memory:    137MB   164MB   162MB
Efficiency: 1x    10.3x   64.5x

Sub-linear Scaling: ✅ 검증 완료
```

**Tags**: `#Spark` `#Performance` `#Prediction` `#Scaling`

**시리즈**:
- Phase 1: 베이스라인 & 버그
- Phase 2: Sub-linear Scaling
- **Phase 3: 예측 검증 (완료)**
