# MacBook M2 Pro 32GBì—ì„œ 1ì–µ ê±´ ì²˜ë¦¬ ë¶„ì„

## ğŸ–¥ï¸ í•˜ë“œì›¨ì–´ ìŠ¤í™

```
MacBook M2 Pro
- CPU: 10-12 ì½”ì–´ (Performance + Efficiency)
- RAM: 32GB í†µí•© ë©”ëª¨ë¦¬
- SSD: 512GB ~ 2TB (ì½ê¸°: ~5GB/s, ì“°ê¸°: ~4GB/s)
- ì•„í‚¤í…ì²˜: ARM64 (Apple Silicon)
```

---

## ğŸ“Š ë°ì´í„° í¬ê¸° ì¶”ì •

### í˜„ì¬ (10,000ê±´)
```
Raw Parquet: ~2MB
Bronze Delta: ~5MB
Silver Delta: ~5MB
Gold Delta: ~10MB
ì´ ìŠ¤í† ë¦¬ì§€: ~22MB
```

### 1ì–µ ê±´ (10,000ë°°)
```
Raw Parquet: ~2GB
Bronze Delta: ~5GB
Silver Delta: ~5GB
Gold Delta (Fact + Dimensions): ~10GB
Transaction Log: ~500MB
ì´ ìŠ¤í† ë¦¬ì§€: ~22.5GB

âœ… ìŠ¤í† ë¦¬ì§€: ë¬¸ì œì—†ìŒ (ì¶©ë¶„í•œ ê³µê°„)
```

---

## âš¡ ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„

### 1. ë°ì´í„° ìƒì„± (Faker)

```bash
uv run python data_generator/generate_all.py --records 100000000
```

**ì˜ˆìƒ ì‹œê°„: 30ë¶„ ~ 1ì‹œê°„**

```python
# ë³‘ëª©: Python ë‹¨ì¼ ìŠ¤ë ˆë“œ
# ì´ˆë‹¹ ìƒì„±: ~50,000ê±´
# 100,000,000ê±´ / 50,000 = 2,000ì´ˆ = 33ë¶„

ì‹¤ì œ ìš”ì¸:
- Faker í˜¸ì¶œ ì˜¤ë²„í—¤ë“œ
- Pandas DataFrame ìƒì„±
- Parquet ì“°ê¸° (ì••ì¶•)

ìµœì í™” ë°©ë²•:
- ë©€í‹°í”„ë¡œì„¸ì‹± ì‚¬ìš©
- ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì €ì¥ (10ë§Œ ê±´ì”©)
```

### 2. Bronze Ingestion

```bash
uv run python jobs/run_pipeline.py
```

**ì˜ˆìƒ ì‹œê°„: 2-3ë¶„**

```
ì‘ì—…:
1. Parquet ì½ê¸°: ~30ì´ˆ
   - 2GB / 5GB/s = 0.4ì´ˆ (ì´ë¡ ê°’)
   - ì‹¤ì œ: ì••ì¶• í•´ì œ, íŒŒì‹± í¬í•¨ ~30ì´ˆ

2. Delta Lake ì“°ê¸°: ~2ë¶„
   - ë©”íƒ€ë°ì´í„° ì¶”ê°€
   - Parquet íŒŒì¼ ìƒì„±
   - Transaction Log ì‘ì„±

ë©”ëª¨ë¦¬ ì‚¬ìš©: ~8GB
- Spark Driver: 2GB
- Executor: 4GB
- ë²„í¼: 2GB
```

### 3. Silver Transformation

**ì˜ˆìƒ ì‹œê°„: 5-10ë¶„**

```
ì‘ì—…:
1. Delta Lake ì½ê¸°: ~1ë¶„
2. ì¤‘ë³µ ì œê±° (dropDuplicates): ~3ë¶„
   - ì „ì²´ ë°ì´í„° ìŠ¤ìº” í•„ìš”
   - í•´ì‹œ í…Œì´ë¸” ìƒì„±
3. ê²€ì¦ (filter): ~30ì´ˆ
4. UDF ì ìš© (normalize): ~2ë¶„
5. Delta Lake Merge: ~3ë¶„

ë©”ëª¨ë¦¬ ì‚¬ìš©: ~15GB
- ì¤‘ë³µ ì œê±° ì‹œ í•´ì‹œ í…Œì´ë¸”: ~8GB
- Shuffle ë²„í¼: ~4GB
- ê¸°íƒ€: ~3GB

âš ï¸ ì£¼ì˜: ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥ì„± ìˆìŒ
```

### 4. Gold Layer (Dimension + Fact)

**ì˜ˆìƒ ì‹œê°„: 10-15ë¶„**

```
ì‘ì—…:
1. Dimension í…Œì´ë¸” ìƒì„±: ~1ë¶„
   - dim_date: 731ê±´ (ë¹ ë¦„)
   - dim_merchant: 41ê±´ (ë¹ ë¦„)
   - dim_category: 18ê±´ (ë¹ ë¦„)

2. Fact í…Œì´ë¸” ìƒì„±: ~10ë¶„
   - Silver ì½ê¸°: ~1ë¶„
   - Dimension ì¡°ì¸ (3ê°œ): ~5ë¶„
     * Broadcast Join ì‚¬ìš© (Dimension ì‘ìŒ)
   - Surrogate Key ìƒì„±: ~2ë¶„
   - Partitioning ì“°ê¸°: ~2ë¶„

ë©”ëª¨ë¦¬ ì‚¬ìš©: ~20GB
- Silver ë°ì´í„°: ~10GB
- Join ë²„í¼: ~6GB
- ì¶œë ¥ ë²„í¼: ~4GB

âš ï¸ ì£¼ì˜: ë©”ëª¨ë¦¬ ì••ë°• ì‹¬í•¨
```

### 5. Analysis

**ì˜ˆìƒ ì‹œê°„: 1-2ë¶„**

```
ì‘ì—…:
- í…Œì´ë¸” ë¡œë“œ: ~30ì´ˆ
- ì›”ë³„ ì§‘ê³„: ~30ì´ˆ
- ì¹´í…Œê³ ë¦¬ ì§‘ê³„: ~20ì´ˆ
- Top ìƒì : ~20ì´ˆ

ë©”ëª¨ë¦¬ ì‚¬ìš©: ~5GB
âœ… ë¬¸ì œì—†ìŒ
```

---

## ğŸ¯ ì´ ì˜ˆìƒ ì‹œê°„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ë‹¨ê³„              â”‚ ì‹œê°„      â”‚ ë©”ëª¨ë¦¬   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. ë°ì´í„° ìƒì„±    â”‚ 30-60ë¶„   â”‚ 4GB     â”‚
â”‚ 2. Bronze         â”‚ 2-3ë¶„     â”‚ 8GB     â”‚
â”‚ 3. Silver         â”‚ 5-10ë¶„    â”‚ 15GB    â”‚
â”‚ 4. Gold           â”‚ 10-15ë¶„   â”‚ 20GB    â”‚
â”‚ 5. Analysis       â”‚ 1-2ë¶„     â”‚ 5GB     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ì´ ì‹œê°„           â”‚ 50-90ë¶„   â”‚ ìµœëŒ€ 20GBâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… ì‹¤í–‰ ê°€ëŠ¥: ì˜ˆ
âš ï¸ ë©”ëª¨ë¦¬ ì••ë°•: ìˆìŒ (ìµœì í™” í•„ìš”)
```

---

## ğŸš¨ ì˜ˆìƒ ë¬¸ì œì 

### 1. ë©”ëª¨ë¦¬ ë¶€ì¡± (OOM - Out of Memory)

**ì¦ìƒ**:
```
25/12/03 17:00:00 ERROR Executor: Exception in task
java.lang.OutOfMemoryError: Java heap space
```

**ë°œìƒ ì‹œì **:
- Silver ì¤‘ë³µ ì œê±° (dropDuplicates)
- Gold Fact í…Œì´ë¸” ì¡°ì¸

**í•´ê²° ë°©ë²•**:
```python
# 1. Spark ë©”ëª¨ë¦¬ ì„¤ì • ì¦ê°€
spark = SparkSession.builder \
    .config("spark.driver.memory", "8g") \
    .config("spark.executor.memory", "16g") \
    .config("spark.memory.fraction", "0.8") \
    .getOrCreate()

# 2. Partition ìˆ˜ ì¦ê°€ (ë©”ëª¨ë¦¬ ë¶„ì‚°)
df.repartition(200)  # ê¸°ë³¸ 200 â†’ 400

# 3. ë°°ì¹˜ ì²˜ë¦¬
for i in range(10):
    df_batch = df.filter(col("id") % 10 == i)
    process(df_batch)
```

### 2. Shuffle ë³‘ëª©

**ì¦ìƒ**:
```
Stage ì§„í–‰ë¥ ì´ 99%ì—ì„œ ë©ˆì¶¤
Shuffle Read/Writeê°€ ëŠë¦¼
```

**ì›ì¸**:
- ì¤‘ë³µ ì œê±°, ì¡°ì¸ ì‹œ Shuffle ë°œìƒ
- ë””ìŠ¤í¬ I/O ë³‘ëª©

**í•´ê²° ë°©ë²•**:
```python
# 1. Broadcast Join ì‚¬ìš© (ì‘ì€ í…Œì´ë¸”)
df.join(broadcast(dim_table), ...)

# 2. Shuffle Partition ì¡°ì •
spark.conf.set("spark.sql.shuffle.partitions", "400")

# 3. AQE (Adaptive Query Execution) í™œìš©
spark.conf.set("spark.sql.adaptive.enabled", "true")
```

### 3. ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

**ì¦ìƒ**:
```
No space left on device
```

**ì›ì¸**:
- Delta Lake ë²„ì „ ì´ë ¥ ëˆ„ì 
- Shuffle ì„ì‹œ íŒŒì¼

**í•´ê²° ë°©ë²•**:
```python
# 1. VACUUM (ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ)
from delta.tables import DeltaTable
delta_table = DeltaTable.forPath(spark, "data/silver/transactions")
delta_table.vacuum(0)  # ì¦‰ì‹œ ì‚­ì œ (ì£¼ì˜!)

# 2. Shuffle ë””ë ‰í† ë¦¬ ì •ë¦¬
spark.conf.set("spark.local.dir", "/path/to/large/disk")
```

---

## ğŸ’¡ ìµœì í™” ì „ëµ

### 1. ë°ì´í„° ìƒì„± ìµœì í™”

```python
# ë©€í‹°í”„ë¡œì„¸ì‹± ì‚¬ìš©
from multiprocessing import Pool

def generate_batch(batch_id):
    gen = TransactionGenerator(seed=42 + batch_id)
    return gen.generate_card_transactions(1000000)

with Pool(8) as p:  # 8ê°œ í”„ë¡œì„¸ìŠ¤
    results = p.map(generate_batch, range(100))
    
# ì‹œê°„: 60ë¶„ â†’ 15ë¶„
```

### 2. Spark ì„¤ì • ìµœì í™”

```python
# utils/spark_session.py
def create_spark_session_optimized():
    return SparkSession.builder \
        .appName("FinanceDataPlatform") \
        .config("spark.driver.memory", "8g") \
        .config("spark.executor.memory", "16g") \
        .config("spark.sql.shuffle.partitions", "400") \
        .config("spark.sql.adaptive.enabled", "true") \
        .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
        .config("spark.sql.adaptive.skewJoin.enabled", "true") \
        .config("spark.memory.fraction", "0.8") \
        .config("spark.memory.storageFraction", "0.3") \
        .master("local[*]") \
        .getOrCreate()
```

### 3. ë°°ì¹˜ ì²˜ë¦¬

```python
# jobs/silver_transformation.py
def transform_to_silver_batched(spark, bronze_path, silver_path):
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬"""
    
    # ë‚ ì§œë³„ë¡œ ë¶„í•  ì²˜ë¦¬
    dates = spark.read.format("delta").load(bronze_path) \
        .select("transaction_date").distinct().collect()
    
    for date_row in dates:
        date = date_row.transaction_date
        
        # í•˜ë£¨ì¹˜ ë°ì´í„°ë§Œ ì²˜ë¦¬
        df_batch = spark.read.format("delta").load(bronze_path) \
            .filter(col("transaction_date") == date)
        
        # ë³€í™˜
        df_transformed = transform(df_batch)
        
        # Append
        df_transformed.write.format("delta") \
            .mode("append").save(silver_path)
```

### 4. Partitioning ì „ëµ

```python
# ë‚ ì§œë³„ íŒŒí‹°ì…”ë‹
df.write.format("delta") \
    .partitionBy("year", "month") \
    .save("data/silver/transactions")

# ì¥ì :
# - ë‚ ì§œ í•„í„° ì¿¼ë¦¬ ë¹ ë¦„
# - ë©”ëª¨ë¦¬ ì‚¬ìš© ê°ì†Œ
# - ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨ ì¦ê°€
```

---

## ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ

### í˜„ì¬ (10,000ê±´)
```
ì´ ì‹œê°„: 3ë¶„
ë©”ëª¨ë¦¬: 2GB
ìŠ¤í† ë¦¬ì§€: 22MB
```

### ìµœì í™” ì—†ì´ (1ì–µ ê±´)
```
ì´ ì‹œê°„: 50-90ë¶„
ë©”ëª¨ë¦¬: 20GB (ì••ë°•)
ìŠ¤í† ë¦¬ì§€: 22.5GB
ì‹¤íŒ¨ ê°€ëŠ¥ì„±: 30%
```

### ìµœì í™” í›„ (1ì–µ ê±´)
```
ì´ ì‹œê°„: 30-40ë¶„
ë©”ëª¨ë¦¬: 16GB (ì•ˆì •)
ìŠ¤í† ë¦¬ì§€: 22.5GB
ì‹¤íŒ¨ ê°€ëŠ¥ì„±: 5%
```

---

## ğŸ¯ ì‹¤ì „ ê¶Œì¥ì‚¬í•­

### ë‹¨ê³„ë³„ ì ‘ê·¼

```bash
# 1ë‹¨ê³„: 10ë§Œ ê±´ (10ë°°)
uv run python data_generator/generate_all.py --records 100000
uv run python jobs/run_pipeline.py
# ì˜ˆìƒ: 5ë¶„, ë©”ëª¨ë¦¬ 3GB

# 2ë‹¨ê³„: 100ë§Œ ê±´ (100ë°°)
uv run python data_generator/generate_all.py --records 1000000
uv run python jobs/run_pipeline.py
# ì˜ˆìƒ: 10ë¶„, ë©”ëª¨ë¦¬ 6GB

# 3ë‹¨ê³„: 1000ë§Œ ê±´ (1000ë°°)
uv run python data_generator/generate_all.py --records 10000000
uv run python jobs/run_pipeline.py
# ì˜ˆìƒ: 20ë¶„, ë©”ëª¨ë¦¬ 12GB

# 4ë‹¨ê³„: 1ì–µ ê±´ (10000ë°°)
# ìµœì í™” ì ìš© í›„ ì‹¤í–‰
```

### ëª¨ë‹ˆí„°ë§

```bash
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
watch -n 1 'ps aux | grep spark'

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
du -sh data/*

# Spark UI í™•ì¸
# http://localhost:4040
```

---

## ğŸ”® ì˜ˆìƒ ê²°ê³¼

### ì„±ê³µ ì‹œë‚˜ë¦¬ì˜¤ (70% í™•ë¥ )

```
âœ… ë°ì´í„° ìƒì„±: ì™„ë£Œ (30ë¶„)
âœ… Bronze: ì™„ë£Œ (3ë¶„)
âœ… Silver: ì™„ë£Œ (8ë¶„, ë©”ëª¨ë¦¬ ì••ë°•)
âœ… Gold: ì™„ë£Œ (12ë¶„, ë©”ëª¨ë¦¬ ì••ë°•)
âœ… Analysis: ì™„ë£Œ (2ë¶„)

ì´ ì‹œê°„: ~55ë¶„
ìµœì¢… ìŠ¤í† ë¦¬ì§€: 22.5GB
```

### ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤ (30% í™•ë¥ )

```
âœ… ë°ì´í„° ìƒì„±: ì™„ë£Œ
âœ… Bronze: ì™„ë£Œ
âŒ Silver: OOM ì—ëŸ¬ (ì¤‘ë³µ ì œê±° ì¤‘)

í•´ê²°ì±…:
1. Spark ë©”ëª¨ë¦¬ ì¦ê°€
2. ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì „í™˜
3. Partition ìˆ˜ ì¦ê°€
```

---

## ğŸ’ª ìµœì¢… ê²°ë¡ 

### MacBook M2 Pro 32GBì—ì„œ 1ì–µ ê±´ ì²˜ë¦¬

**ê°€ëŠ¥ ì—¬ë¶€**: âœ… **ê°€ëŠ¥í•¨**

**ì¡°ê±´**:
1. Spark ë©”ëª¨ë¦¬ ì„¤ì • ìµœì í™” í•„ìˆ˜
2. ë°°ì¹˜ ì²˜ë¦¬ ê¶Œì¥ (ì•ˆì •ì„±)
3. ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ (50GB ì´ìƒ)
4. ë‹¤ë¥¸ ì•± ì¢…ë£Œ (ë©”ëª¨ë¦¬ í™•ë³´)

**ì˜ˆìƒ ì‹œê°„**: 30-60ë¶„

**ê¶Œì¥ ì „ëµ**:
```
1. 10ë§Œ ê±´ë¶€í„° ì‹œì‘ (í…ŒìŠ¤íŠ¸)
2. ì ì§„ì ìœ¼ë¡œ ì¦ê°€ (100ë§Œ â†’ 1000ë§Œ)
3. ìµœì í™” ì ìš©
4. 1ì–µ ê±´ ë„ì „
```

**ëŒ€ì•ˆ**:
- í´ë¼ìš°ë“œ ì‚¬ìš© (AWS EMR, Databricks)
- ë” ê°•ë ¥í•œ í•˜ë“œì›¨ì–´ (64GB RAM)
- ë°ì´í„° ìƒ˜í”Œë§ (1000ë§Œ ê±´ìœ¼ë¡œ ì œí•œ)

---

## ğŸš€ ë°”ë¡œ ì‹œë„í•´ë³´ê¸°

```bash
# 1. ìµœì í™”ëœ Spark ì„¤ì • ì ìš©
# utils/spark_session.py ìˆ˜ì •

# 2. 10ë§Œ ê±´ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
uv run python data_generator/generate_all.py --records 100000
uv run python jobs/run_pipeline.py

# 3. ì„±ê³µí•˜ë©´ 100ë§Œ ê±´
uv run python data_generator/generate_all.py --records 1000000
uv run python jobs/run_pipeline.py

# 4. ìµœì¢… 1ì–µ ê±´ ë„ì „!
uv run python data_generator/generate_all.py --records 100000000
uv run python jobs/run_pipeline.py
```

**í–‰ìš´ì„ ë¹•ë‹ˆë‹¤!** ğŸ€
