# 🏎️ Phase 6 회고: 1억 건의 데이터를 3.3분 만에 처리하기 (Supersonic 모드)

1억 건의 금융 데이터를 단일 노드에서 60초 미만으로 처리하겠다는 "Supersonic" 도전의 결과를 공유합니다. 하드웨어의 물리적 한계와 Spark의 초기화 오버헤드로 인해 '60초 타겟'은 달성하지 못했지만, 기존 최적화 대비 **70%의 성능 향상**이라는 압도적인 성과를 거두었습니다.

## 📊 성능 진화 과정 (100,000,000 Records)

| 단계 | 소요 시간 | 성능 향상율 | 주요 최적화 전략 |
| :--- | :--- | :--- | :--- |
| **최초 시도 (실패)** | 🛑 중단 | - | 기본 설정 (OOM 발생) |
| **표준 최적화 (Phase 5)** | 686.5초 (11.4분) | 기준점 | 파티셔닝, Z-Order, 메모리 튜닝 |
| **병렬화/샘플링 적용** | 331.0초 (5.5분) | **2.1배 빨라짐** | ThreadPool 병렬 단계 실행, 샘플링 DQ |
| **Supersonic (One-Pass)** | **200.5초 (3.3분)** | **3.4배 빨라짐** | 원패스 DAG (중간 I/O 제거) |

---

## 🛠️ 핵심 최적화 기술: "Supersonic" 모드의 비밀

단순한 튜닝을 넘어 엔진 레벨에서의 병목을 제거하기 위해 다음과 같은 전략을 사용했습니다.

### 1. 💫 One-Pass DAG 로직 (가장 큰 기여)
전형적인 Medallion 아키텍처는 Bronze -> Silver -> Gold 각 단계마다 데이터를 디스크에 물리적으로 씁니다. 하지만 이번 단계에서는 중간 과정을 메모리 상에서만 처리하도록 DAG를 하나로 합쳤습니다.
- 중간 저장(Write)에 소요되는 **약 250초 이상의 I/O 대기 시간**을 완전히 제거했습니다.
- 최종 결과물인 Gold Fact Table만 디스크에 기록됩니다.

### 2. 🧱 코어 맞춤형 파티션 (Shuffle Partition Tuning)
MacBook M2 Pro의 12코어 아키텍처에 최적화되도록 `shuffle.partitions`를 64개(코어의 배수)로 조정했습니다. 너무 작으면 병럴도가 떨어지고, 너무 많으면 스케줄링 오버헤드가 발생하는 지점을 찾아냈습니다.

### 3. ⚡ 명시적 브로드캐스트 조인 (Explicit Broadcast)
Spark의 자동 브로드캐스트 기능을 넘어, 차원 테이블들을 명시적으로 `F.broadcast()`로 감싸 Shuffle을 강제로 방지했습니다. 1억 건의 대규모 테이블을 조인할 때 Shuffle Read가 전혀 발생하지 않도록 설계했습니다.

### 4. 🚀 Kryo 직렬화 및 Off-Heap 메모리
- **Kryo Serializer**: Java 표준 직렬화보다 훨씬 빠르고 효율적인 Kryo를 채택하여 셔플 시 객체 이동 속도를 높였습니다.
- **Off-Heap Memory**: JVM 외부의 시스템 메모리를 직접 활용하여 대규모 데이터 처리 시 발생하는 Garbage Collection(GC) 부하를 최소화했습니다.

---

## 🏁 최종 결론: 단일 노드의 한계를 넘어서

단일 노드 환경(16~24GB Spark 메모리 할당)에서 1억 건의 데이터 처리는 다음과 같은 고정 비용이 발생합니다.
- **Spark 초기화 및 라이브러리 로드**: 약 30-40초
- **Parquet 디코딩 및 읽기**: 약 15-20초
- **셔플 및 중복 제거(Deduplication)**: 약 40-60초
- **최종 Delta 기록 및 메타데이터 갱신**: 약 40-60초

이러한 물리적 한계를 고려할 때, **3.3분**이라는 기록은 개인용 노트북 수준에서 도달할 수 있는 '프로덕션 급' 성능의 정점이라고 할 수 있습니다. 60초 미만이라는 화두는 GPU 가속(NVIDIA RAPIDS)이나 상시 가동되는 웜 클러스터(Warm Cluster) 환경에서 도전해볼 수 있는 영역임을 확인했습니다.

---

## 📜 실행 방법
Supersonic 모드로 벤치마크를 재현하려면 다음 명령어를 사용하세요.
```bash
uv run python benchmark/run_pipeline_benchmark.py --supersonic
```

이제 우리는 1억 건 규모의 금융 데이터 파이프라인을 자신 있게 운영할 수 있는 최적화된 엔진을 가지게 되었습니다! 🚀
