# Personal Finance Data Platform

Apache Spark ê¸°ë°˜ ê°œì¸ ê¸ˆìœµ ë°ì´í„° ë¶„ì„ í”Œë«í¼ (Medallion Architecture + Star Schema)

## ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ

- Apache Spark ë°°ì¹˜ ì²˜ë¦¬ í•™ìŠµ
- Medallion Architecture (Bronze/Silver/Gold) êµ¬í˜„
- Star Schema ê¸°ë°˜ ë°ì´í„° ë§ˆíŠ¸ ì„¤ê³„
- Delta Lakeë¥¼ í™œìš©í•œ ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤ êµ¬ì¶•

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```
Raw Data (Parquet)
    â†“
ğŸ”¶ Bronze Layer (Delta Lake) - ì›ë³¸ ë°ì´í„°
    â†“
ğŸ”· Silver Layer (Delta Lake) - ì •ì œëœ ë°ì´í„°
    â†“
ğŸŒŸ Gold Layer (Star Schema) - ë¶„ì„ìš© ë°ì´í„° ë§ˆíŠ¸
    â”œâ”€â”€ dim_date
    â”œâ”€â”€ dim_category
    â”œâ”€â”€ dim_merchant
    â””â”€â”€ fact_transactions
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# uv ì„¤ì¹˜ (macOS)
curl -LsSf https://astral.sh/uv/install.sh | sh

# í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
uv venv
source .venv/bin/activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
uv pip install pyspark==3.5.0 delta-spark==3.0.0 faker==22.0.0 pandas pyarrow
```

### 2. ë°ì´í„° ìƒì„±

```bash
# 10ë§Œê±´ì˜ ì¹´ë“œ ê±°ë˜ ë°ì´í„° ìƒì„±
uv run python data_generator/generate_all.py --records 100000
```

### 3. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
# ì „ì²´ ETL íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
uv run python jobs/run_pipeline.py
```

### 4. ë°ì´í„° ë¶„ì„

```bash
# ë¹ ë¥¸ ë¶„ì„ ì‹¤í–‰
uv run python analytics/quick_analysis.py
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
finance-spark-platform/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Parquet ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ bronze/                 # Bronze Layer (Delta)
â”‚   â”œâ”€â”€ silver/                 # Silver Layer (Delta)
â”‚   â””â”€â”€ gold/                   # Gold Layer (Star Schema)
â”œâ”€â”€ data_generator/             # ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ jobs/                       # Spark Job ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ analytics/                  # ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ schemas/                    # ìŠ¤í‚¤ë§ˆ ì •ì˜
â”œâ”€â”€ utils/                      # ìœ í‹¸ë¦¬í‹°
â””â”€â”€ docs/                       # ë¬¸ì„œ
```

## ğŸ“Š ë°ì´í„° ëª¨ë¸

### Star Schema

```
        dim_date
           â”‚
           â”œâ”€â”€ dim_category
           â”‚        â”‚
    fact_transactions (ì¤‘ì‹¬)
           â”‚        â”‚
           â”œâ”€â”€ dim_merchant
```

## ğŸ” ë¶„ì„ ì¿¼ë¦¬ ì˜ˆì‹œ

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Analysis").getOrCreate()

# ì›”ë³„ ì¹´í…Œê³ ë¦¬ ì§€ì¶œ ë¶„ì„
spark.sql("""
    SELECT 
        d.year, d.month_name,
        c.level_1 as category,
        SUM(f.amount) as total_amount
    FROM fact_transactions f
    JOIN dim_date d ON f.date_key = d.date_key
    JOIN dim_category c ON f.category_key = c.category_key
    GROUP BY d.year, d.month_name, c.level_1
    ORDER BY d.year, d.month, total_amount DESC
""").show()
```

## ğŸ“ˆ ë¶„ì„ ê²°ê³¼

10,000ê±´ ê±°ë˜ ë°ì´í„° ë¶„ì„ ê²°ê³¼:
- **ì´ ì§€ì¶œ**: â‚©646,895,601
- **í‰ê·  ê±°ë˜ì•¡**: â‚©64,690
- **Top ì¹´í…Œê³ ë¦¬**: ì£¼ê±°(42%), ì‡¼í•‘(20%), ì‹ë¹„(13%)
- **ì£¼ë§ vs í‰ì¼**: í‰ê·  ê±°ë˜ì•¡ ê±°ì˜ ë™ì¼ (ì°¨ì´ 0.2%)

ìì„¸í•œ ë¶„ì„ ê²°ê³¼ëŠ” [docs/analysis_results.md](docs/analysis_results.md)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

## ğŸ“š í•™ìŠµ í¬ì¸íŠ¸

- âœ… Spark DataFrame API
- âœ… Delta Lake (ACID, Time Travel)
- âœ… Medallion Architecture
- âœ… Star Schema ì„¤ê³„
- âœ… Partitioning ì „ëµ
- âœ… UDF (User Defined Functions)

## ğŸ“– ìƒì„¸ ë¬¸ì„œ

- [ë¡œë“œë§µ](docs/roadmap.md) - ì „ì²´ í”„ë¡œì íŠ¸ ë¡œë“œë§µ
- [ë¶„ì„ ê²°ê³¼](docs/analysis_results.md) - ë°ì´í„° ë¶„ì„ ì¸ì‚¬ì´íŠ¸
- [ì‹¤í–‰ ê°€ì´ë“œ](docs/walkthrough.md) - íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê³¼ì •
